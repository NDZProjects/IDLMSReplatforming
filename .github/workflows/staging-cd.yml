name: Build and Deploy License API

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Deployment environment"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          - stage
          - prod

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      run_infra: ${{ steps.filter.outputs.infra }}
      run_build: ${{ steps.filter.outputs.build }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Filter Changes
        id: filter
        uses: dorny/paths-filter@v3
        with:
          filters: |
            infra:
              - 'infra/**'
            build:
              - 'docker/**'
              - 'docker-compose.yml'
              - 'src/**'

  deploy:
    needs: detect-changes
    if: ${{ needs.detect-changes.outputs.run_infra == 'true' || needs.detect-changes.outputs.run_build == 'true' }}
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}

    env:
      AWS_REGION: us-east-1
      TF_BUCKET: my-terraform-state-bckt43
      BACKUP_BUCKET: idlms-website-built-artifact
      ENV: ${{ github.event.inputs.environment }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Terraform Apply VPC
        if: ${{ needs.detect-changes.outputs.run_infra == 'true' }}
        run: |
          cd infra/vpc
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${ENV}/vpc/terraform.tfstate"
          terraform apply -auto-approve -var-file="${ENV}.tfvars"

      - name: Terraform Apply NLB
        if: ${{ needs.detect-changes.outputs.run_infra == 'true' }}
        run: |
          cd infra/nlb
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${ENV}/nlb/terraform.tfstate"
          terraform apply -auto-approve -var-file="${ENV}.tfvars"

      - name: Terraform Apply HTTP API
        if: ${{ needs.detect-changes.outputs.run_infra == 'true' }}
        run: |
          cd infra/http-api
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${ENV}/http-api/terraform.tfstate"
          terraform apply -auto-approve -var-file="${ENV}.tfvars"

      - name: Terraform Apply CloudWatch
        if: ${{ needs.detect-changes.outputs.run_infra == 'true' }}
        run: |
          cd infra/cloudwatch
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${ENV}/cloudwatch/terraform.tfstate"
          terraform apply -auto-approve -var-file="${ENV}.tfvars"

      - name: Generate Docker Build Tag
        run: echo "BUILD_TAG=license-api-$(date +'%d%m%Y%H%M%S')" >> $GITHUB_ENV

      - name: Build Docker Image
        run: |
          docker build -t $BUILD_TAG -f docker/Dockerfile src
          mkdir -p docker/output
          docker save $BUILD_TAG | gzip > docker/output/$BUILD_TAG.tar.gz

      - name: Upload Docker Image to S3
        run: |
          aws s3 cp docker/output/$BUILD_TAG.tar.gz s3://${BACKUP_BUCKET}/docker-images/$ENV/$BUILD_TAG.tar.gz

      - name: Upload docker-compose.yml to S3
        run: |
          aws s3 cp docker/docker-compose.yml s3://${BACKUP_BUCKET}/docker-compose/$ENV/docker-compose.yml

      - name: Generate .env from GitHub Secrets
        run: |
          mkdir -p docker/output
          cat <<EOF > docker/output/.env
PORT=${{ secrets.PORT }}
APP_NAME=${{ secrets.APP_NAME }}
NODE_ENV=${{ secrets.NODE_ENV }}
SALT_ROUNDS=${{ secrets.SALT_ROUNDS }}
JWT_SECRET=${{ secrets.JWT_SECRET }}
API_CLIENT_JWT_EXPIRES_IN=${{ secrets.API_CLIENT_JWT_EXPIRES_IN }}
EMAIL_SENDER=${{ secrets.EMAIL_SENDER }}
AUTO_RUN_MIGRATIONS=${{ secrets.AUTO_RUN_MIGRATIONS }}
DB_HOST=${{ secrets.DB_HOST }}
DB_PORT=${{ secrets.DB_PORT }}
DB_USERNAME=${{ secrets.DB_USERNAME }}
DB_PASSWORD=${{ secrets.DB_PASSWORD }}
DB_NAME=${{ secrets.DB_NAME }}
EMAIL_PORT=${{ secrets.EMAIL_PORT }}
EMAIL_HOST=${{ secrets.EMAIL_HOST }}
EMAIL_USER=${{ secrets.EMAIL_USER }}
EMAIL_PASS=${{ secrets.EMAIL_PASS }}
EMAIL_SECURE=${{ secrets.EMAIL_SECURE }}
ORIGINS=${{ secrets.ORIGINS }}
LOCAL_URL=${{ secrets.LOCAL_URL }}
STAGING_URL=${{ secrets.STAGING_URL }}
PAYMENT_KEY=${{ secrets.PAYMENT_KEY }}
API_BASE_URL=${{ secrets.API_BASE_URL }}
API_OPERATION=${{ secrets.API_OPERATION }}
USERNAME=${{ secrets.USERNAME }}
SECRETE=${{ secrets.SECRETE }}
MERCHANT=${{ secrets.MERCHANT }}
INTERACTION_OPERETION=${{ secrets.INTERACTION_OPERETION }}
MERCHANT_NAME=${{ secrets.MERCHANT_NAME }}
NIN_ENDPOINT=${{ secrets.NIN_ENDPOINT }}
NIN_API_KEY=${{ secrets.NIN_API_KEY }}
NIN_API_SECRETE=${{ secrets.NIN_API_SECRETE }}
NIN_VERIFICATION=${{ secrets.NIN_VERIFICATION }}
NIN_AUTH_USERNAME=${{ secrets.NIN_AUTH_USERNAME }}
NIN_AUTH_PASSWORD=${{ secrets.NIN_AUTH_PASSWORD }}
ATTACHMENT_S3_BUCKET=${{ secrets.ATTACHMENT_S3_BUCKET }}
APP_AWS_REGION=${{ secrets.APP_AWS_REGION }}
APP_AWS_SECRET_ACCESS_KEY=${{ secrets.APP_AWS_SECRET_ACCESS_KEY }}
APP_AWS_ACCESS_KEY_ID=${{ secrets.APP_AWS_ACCESS_KEY_ID }}
APP_AWS_ACCOUNT_ID=${{ secrets.APP_AWS_ACCOUNT_ID }}
APP_AWS_NOTIFICATIONS_QUEUE_NAME=${{ secrets.APP_AWS_NOTIFICATIONS_QUEUE_NAME }}
OTP_LOGIN_KEY=${{ secrets.OTP_LOGIN_KEY }}
OTP_LOGIN_EXPIRED_TIME=${{ secrets.OTP_LOGIN_EXPIRED_TIME }}
JWT_OTP_KEY=${{ secrets.JWT_OTP_KEY }}
JWT_OTP_LOGIN_EXPIRED_TIME=${{ secrets.JWT_OTP_LOGIN_EXPIRED_TIME }}
EOF

      - name: Upload generated .env file to S3
        run: |
          aws s3 cp docker/output/.env s3://${BACKUP_BUCKET}/env/$ENV/.env

      - name: Deploy using SSM
        run: |
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=Backend API IDLMS-${ENV}" "Name=instance-state-name,Values=running" \
            --query "Reservations[].Instances[].InstanceId" \
            --output text)

          echo "Deploying to instance: $INSTANCE_ID"

          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy Docker image and docker-compose via S3" \
            --parameters commands="[ 
              \"set -e\",
              \"if ! command -v aws &> /dev/null; then curl 'https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip' -o 'awscliv2.zip' && unzip awscliv2.zip && ./aws/install; fi\",
              \"if ! command -v docker &> /dev/null; then apt update && apt install -y docker.io docker-compose && systemctl enable docker && systemctl start docker; fi\",
              \"mkdir -p /home/ubuntu/backup /home/ubuntu/src\",
              \"aws s3 cp s3://${BACKUP_BUCKET}/docker-compose/${ENV}/docker-compose.yml /home/ubuntu/docker-compose.yml\",
              \"aws s3 cp s3://${BACKUP_BUCKET}/env/${ENV}/.env /home/ubuntu/src/.env\",
              \"aws s3 cp s3://${BACKUP_BUCKET}/docker-images/${ENV}/${BUILD_TAG}.tar.gz /home/ubuntu/app.tar.gz\",
              \"gunzip -f /home/ubuntu/app.tar.gz\",
              \"docker load < /home/ubuntu/app.tar && cp /home/ubuntu/app.tar /home/ubuntu/backup/last-known-good.tar\",
              \"docker-compose --env-file /home/ubuntu/src/.env -f /home/ubuntu/docker-compose.yml down || true\",
              \"docker-compose --env-file /home/ubuntu/src/.env -f /home/ubuntu/docker-compose.yml up -d || (echo 'Deployment failed. Rolling back...' && docker load < /home/ubuntu/backup/last-known-good.tar && docker-compose --env-file /home/ubuntu/src/.env -f /home/ubuntu/docker-compose.yml up -d)\" 
            ]" \
            --timeout-seconds 600 \
            --output text
